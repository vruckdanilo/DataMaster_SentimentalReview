# compose v2: removed deprecated 'version' key

services:
  # MinIO - S3 Compatible Object Storage
  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9001:9001"
      - "9000:9000"
    command: ["server", "/data", "--console-address", ":9001"]
    volumes:
      - ./mnt/minio/data:/data
    environment:
      MINIO_ACCESS_KEY: "minio"
      MINIO_SECRET_KEY: "minio123"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - data_network

  # MySQL - Database for Hive Metastore
  mysql:
    image: mariadb:10.5.16
    container_name: mysql
    volumes:
      - ./mnt/mysql:/var/lib/mysql
    ports:
      - "3306:3306"
    environment:
      MYSQL_ROOT_PASSWORD: admin
      MYSQL_DATABASE: metastore_db
      MYSQL_USER: admin
      MYSQL_PASSWORD: admin
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - data_network

  # PostgreSQL - Database for Airflow
  postgres-airflow:
    image: postgres:13
    container_name: postgres-airflow
    volumes:
      - ./mnt/postgres:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: "airflow"
      POSTGRES_PASSWORD: "airflow"
      POSTGRES_DB: "airflow_db"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - data_network

  # Apache Airflow Webserver
  airflow-webserver:
    build:
      context: .
      dockerfile: docker/airflow/Dockerfile
    container_name: airflow-webserver
    depends_on:
      postgres-airflow:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-airflow:5432/airflow_db
      - AIRFLOW__CORE__FERNET_KEY=
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=true
    volumes:
      - ./mnt/airflow/dags:/opt/airflow/dags
      - ./mnt/airflow/logs:/opt/airflow/logs
      - ./mnt/airflow/plugins:/opt/airflow/plugins
      - ./mnt/airflow/scripts:/opt/airflow/scripts
      - ./mnt/airflow/raw_data:/opt/airflow/raw_data
      - ./mnt/spark/jobs:/opt/airflow/spark_jobs
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "8089:8080"
    command: webserver
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - data_network

  # Apache Airflow Scheduler
  airflow-scheduler:
    build:
      context: .
      dockerfile: docker/airflow/Dockerfile
    container_name: airflow-scheduler
    depends_on:
      postgres-airflow:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-airflow:5432/airflow_db
      - AIRFLOW__CORE__FERNET_KEY=
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
    volumes:
      - ./mnt/airflow/dags:/opt/airflow/dags
      - ./mnt/airflow/logs:/opt/airflow/logs
      - ./mnt/airflow/plugins:/opt/airflow/plugins
      - ./mnt/airflow/scripts:/opt/airflow/scripts
      - ./mnt/airflow/raw_data:/opt/airflow/raw_data
      - ./mnt/spark/jobs:/opt/airflow/spark_jobs
      - /var/run/docker.sock:/var/run/docker.sock
    command: scheduler
    healthcheck:
      test: ["CMD-SHELL", 'airflow jobs check --job-type SchedulerJob --hostname "$${HOSTNAME}"']
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - data_network

  # Zookeeper for Kafka coordination
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    volumes:
      - ./mnt/zookeeper/data:/var/lib/zookeeper/data
      - ./mnt/zookeeper/logs:/var/lib/zookeeper/log
    healthcheck:
      test: ["CMD-SHELL", "bash -c 'echo > /dev/tcp/localhost/2181'"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - data_network

  # Kafka Broker
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    volumes:
      - ./mnt/kafka/data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "bash -c 'echo > /dev/tcp/localhost/9092'"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - data_network

  # Hive Metastore
  hive-metastore:
    build:
      context: ./docker/hive-metastore
      dockerfile: Dockerfile
    image: hive-metastore:latest
    container_name: hive-metastore
    depends_on:
      mysql:
        condition: service_healthy
    ports:
      - "9083:9083"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9083"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - data_network

  # Build-only base image used by spark-master and spark-worker
  spark-base:
    build:
      context: ./docker/spark/spark-base
      dockerfile: Dockerfile
    image: ${SPARK_BASE_IMAGE:-spark-base:latest}
    networks:
      - data_network
    profiles: ["build"]

  # Spark Master
  spark-master:
    build:
      context: ./docker/spark/spark-master
      dockerfile: Dockerfile
      args:
        SPARK_BASE_IMAGE: ${SPARK_BASE_IMAGE:-spark-base:latest}
    image: ${SPARK_MASTER_IMAGE:-spark-master:latest}
    restart: always
    container_name: spark-master
    ports:
      - "8082:8082"
      - "7077:7077"
    volumes:
      - ./mnt/spark/apps:/opt/spark-apps
      - ./mnt/spark/data:/opt/spark-data
      - ./mnt/spark/jobs:/opt/bitnami/spark/jobs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8082"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - data_network

  # Spark Worker
  spark-worker:
    build:
      context: ./docker/spark/spark-worker
      dockerfile: Dockerfile
      args:
        SPARK_BASE_IMAGE: ${SPARK_BASE_IMAGE:-spark-base:latest}
    image: ${SPARK_WORKER_IMAGE:-spark-worker:latest}
    container_name: spark-worker
    depends_on:
      spark-master:
        condition: service_healthy
    ports:
      - "8081:8081"
    volumes:
      - ./mnt/spark/apps:/opt/spark-apps
      - ./mnt/spark/data:/opt/spark-data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - data_network

  # Trino Coordinator
  trino-coordinator:
    build: ./docker/trino
    container_name: trino-coordinator
    environment:
      - TRINO_NODE_ID=coordinator
    volumes:
      - ./mnt/trino/data:/opt/trino/data
      - ./docker/trino/etc/catalog:/etc/trino/catalog
      - ./docker/trino/etc/node.properties:/etc/trino/node.properties
      - ./docker/trino/etc/config.properties:/etc/trino/config.properties
      - ./docker/trino/etc/jvm.config:/etc/trino/jvm.config
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/info"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - data_network
    depends_on:
      hive-metastore:
        condition: service_healthy
      minio:
        condition: service_healthy

  # Apache Superset
  superset:
    image: apache/superset:latest
    container_name: superset
    ports:
      - "8088:8088"
    environment:
      - SUPERSET_SECRET_KEY=your_secret_key_here
      - PYTHONPATH=/app/superset_home/pythonpath
      - PYTHONNOUSERSITE=1
    volumes:
      - ./mnt/superset:/app/superset_home
      - ./scripts/configuracoesextras.sh:/docker-extra/configuracoesextras.sh:ro
    command: >
      bash -lc "
      export PATH=\"/usr/local/bin:/usr/bin:$$HOME/.local/bin:/app/.venv/bin:$$PATH\"; hash -r;
      bash /docker-extra/configuracoesextras.sh superset || true;
      SUP_CLI=\"$(command -v superset || true)\";
      if [ -n \"$$SUP_CLI\" ]; then SUP_CMD=\"$$SUP_CLI\"; else SUP_CMD=\"python -m superset\"; fi;
      eval \"$$SUP_CMD db upgrade\" &&
      eval \"$$SUP_CMD fab create-admin --username admin --firstname Admin --lastname User --email admin@superset.com --password admin123\" || true &&
      eval \"$$SUP_CMD init\" &&
      eval \"$$SUP_CMD run -h 0.0.0.0 -p 8088\"
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8088/health"]
      start_period: 180s
      interval: 30s
      timeout: 10s
      retries: 10
    networks:
      - data_network

  # Google Maps Mock API - JSON Server
  google-maps-mock:
    image: vimagick/json-server
    container_name: google-maps-mock
    ports:
      - "3001:3000"
    volumes:
      - ./mnt/google-maps-mock/db.json:/data/db.json
    command: ["--host", "0.0.0.0", "--port", "3000", "/data/db.json"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/textsearch"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - data_network
    restart: unless-stopped

networks:
  data_network:
    driver: bridge
