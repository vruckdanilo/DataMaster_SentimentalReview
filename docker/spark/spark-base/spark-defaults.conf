# Spark Configuration for Local Tables
# Delta Lake extensions available but not forced globally
spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension

# S3 Configuration for MinIO (only when explicitly needed)
# spark.hadoop.fs.s3a.endpoint=http://minio:9000
# spark.hadoop.fs.s3a.access.key=minio
# spark.hadoop.fs.s3a.secret.key=minio123
# spark.hadoop.fs.s3a.path.style.access=true
# spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
# spark.hadoop.fs.s3a.connection.ssl.enabled=false

# Hive Metastore Configuration
spark.sql.catalog.hive_metastore=org.apache.spark.sql.hive.thrift.ThriftExternalCatalog
spark.sql.catalog.hive_metastore.uri=thrift://hive-metastore:9083

# Warehouse Configuration (Local)
spark.sql.warehouse.dir=/opt/spark/warehouse
spark.hadoop.javax.jdo.option.ConnectionURL=jdbc:derby:;databaseName=/opt/spark/metastore_db;create=true

# Performance and Memory Settings
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.sql.adaptive.enabled=true
spark.sql.adaptive.coalescePartitions.enabled=true
